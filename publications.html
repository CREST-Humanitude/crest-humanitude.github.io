<!DOCTYPE html>
<html lang="en">
   <head>
      <meta charset="utf-8">
      <title>People</title>
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <meta name="description" content="Research Lab, Home, Velit Aliquet Sagittis University">
      <meta name="author" content="">
      <!-- Le styles -->
      <link href="css/bootstrap.min.css" rel="stylesheet">
      <link href="css/bootstrap-responsive.min.css" rel="stylesheet">
      <link href="css/theme.css" rel="stylesheet">
   </head>
   <body>
      <div class="container">
         <header class="jumbotron subhead" id="overview">
            <p class="lead"> JST CREST 人間と情報環境の共生インタラクション基盤技術の創出と展開 </p>
            <h1>「優しい介護」インタラクションの計算的・脳科学的解明 </h1>
         </header>
<!----------------------------------------------------------------------------------------------------------->	      
         <div class="masthead">
            <div class="navbar">
               <div class="navbar-inner">
                  <div class="container">
                     <ul class="nav">
                        <li><a href="index.html">Home</a></li>
                        <li><a href="people.html">People</a></li>			     
                        <li><a href="research.html">Research</a></li>
                        <li class="active"><a href="publications.html">Publications</a></li>      
                        <li><a href="press.html">Press Release</a></li>                        
                        <li><a href="links.html">Links</a></li>
                     </ul>
                  </div>
               </div>
            </div>
         </div>	      
<!-------------------------------------------------------------------------------->	
         <hr>
         <div class="row-fluid">
            <div class="span3 bs-docs-sidebar" id="navparent">
               <ul class="nav nav-list bs-docs-sidenav" data-spy="affix" data-offset-top="200" data-offset-bottom="260">
                  <li><a class="subhead" href="#2022"> FY2022 </a></li>
                  <li><a class="subhead" href="#2021"> FY2021 </a></li>
                  <li><a class="subhead" href="#2020"> FY2020 </a></li>
                  <li><a class="subhead" href="#2019"> FY2019 </a></li>
                  <li><a class="subhead" href="#2018"> FY2018 </a></li>
                  <li><a class="subhead" href="#2017"> FY2017 </a></li>
               </ul>
            </div>
            <div class="span8 offset0 publication">
               <section id="published">
                  <section id="2022">
                     <h3>FY022</h3>
					 <li>coming soon.
                  </section>
                  <hr>
                  <section id="2021">
                     <h3>FY2021</h3>
<p><b>論文</b> †
<li>Ohshima Yuki, Maeda Kyosuke, Edamoto Yusuke, Nakazawa Atsushi, Visual Place Recognition From Eye Reflection, IEEE Access, 9, pp.57364-57371, 2021.
<li>Akishige Yuguchi, Tetsuya Sano, Gustavo Alfonso Garcia Ricardez, Jun Takamatsu, Atsushi Nakazawa, Tsukasa Ogasawara, Evaluating imitation and rule-based behaviors of eye contact and blinking using an android for conversation, ADVANCED ROBOTICS, 35, 15, pp907-918,2021.
<li>Masaki Kobayashi, Mio Ito, Yasuyuki Iwasa, Yoshiko Motohashi, Ayako Edahiro, Maki Shirobe, Hirohiko Hirano, Yves Gineste, Miwako Honda, The effect of multimodal comprehensive care methodology training on oral health care professionals' empathy for patients with dementia, BMC medical education, 21, 1, pp1-8, 2021.
<li>布井雅人, 吉川左紀子, 中澤篤志, 他者の視線方向・表情と参加者の体勢が介護ベッド上での対人認知に及ぼす影響--ヘッドマウントディスプレイを使用した検討--, 電子情報通信学会論文誌A, 104, 2, pp.40-48, 2021.
<li>Hidenobu Sumioka, Masahiro Shiomi, Miwako Honda, Atsushi Nakazawa, Technical Challenges for Smooth Interaction With Seniors With Dementia: Lessons From Humanitude™, Frontiers in robotics and AI, 8, 650906, 2021.
<li>布井雅人, 吉川左紀子, 中澤篤志, The Influence of the Other’s Gaze Direction, Facial Expressions and the Participant’s Posture on the Interpersonal Cognition on a Nursing Care Bed-Examination Using a Head-mounted Display-, 電子情報通信学会論文誌 A(Web), J104-A, 2, pp.40-48, 2021.
<li>Yusuke Fukuyasu, Hitomi U Kataoka, Miwako Honda, Toshihide Iwase, Hiroko Ogawa, Masaru Sato, Mayu Watanabe, Chikako Fujii, Jun Wada, Jennifer DeSantis?, Mohammadrez a Hojat, Joseph S Gonnella, The effect of Humanitude care methodology on improving empathy: a six-year longitudinal study of medical students in Japan, BMC medical education, 21, 1, 316,2021.
<li>Masaki Kobayashi, Miwako Honda, The effect of a multimodal comprehensive care methodology for family caregivers of people withdementia, BMC geriatrics, 21, 1, 434, 2021.
<li>Huggins, C., Cameron, I. M., Scott, N. W., Williams, J. H., Yoshikawa, S., Sato, W., Cross-cultural differences and psychometric properties of the Japanese Actions and Feelings Questionnaire (J-AFQ), Frontiers in Psychology, 12, 722108, 2021.
<li>Yamamoto Takahisa, Takeuchi Shiki, Nakazawa Atsushi, Image Emotion Recognition Using Visual and Semantic Features Reflecting Emotional and Similar Objects, IEICE TRANSACTIONS on Information and Systems, 104, 10, pp.1691-1701, 2021.
<li>Sato, W., Usui, N., Sawada, R., Kondo, A., Toichi, M., Inoue, Y., Impairment of emotional expression detection after unilateral medial temporal structure resection, Scientific Reports, 11, 1, 20617, 2021.
<li>Shogo Ishikawa, Masashi Onozuka, Atsushi Omata, Ayumi Nakanome, Sota Kayama, Shinya Kiriyama, A Development of a Multimodal Behavior Analysis System for Evaluating Dementia Care Interaction, Companion Publication of the 2021 International Conference on Multimodal Interaction, pp.176-182, 2021.
<li>Sato, W., Ikegami, A., Ishihara, S., Nakauma, M., Funami, T., Yoshikawa, S., Fushiki, T., Brow and masticatory muscle activity senses subjective hedonic experiences during food consumption, Nutrients, 13, 12, 4216, 2021.
<li>浦岡泰之, 吉田康紀, 村田耕一, 木瀬香保利, 北河茜, 冨田定, 古田雅史, 務中達也, 岡田志, マルチデバイス生体計測システム HuME（Human Metrics Explorer）TMの開発と応用, 島津評論, 78, 3 4, pp.245-254, 2021.
<li>Saito, A., Sato, W., Yoshikawa, S., Rapid detection of neutral faces associated with emotional value, Cognition and Emotion, 2021.
<li>Ryo Kurazume, Tomoki Hiramatsu, Masaya Kamei, Daiji Inoue, Akihiro Kawamura, Shoko Miyauchi, Qi An, Development of AR training systems for Humanitude dementia care, Advanced Robotics, 2021.
<li>小俣敦士, 石川翔吾, 中野目あゆみ, 香山壮太, 宗形初枝, 坂根裕, 桐山伸也, 組織全体の認知症ケアスキル向上のためのビデオコーチング環境の実証実験と介入指導インタラクションの分析, 36, 2, pp.491-502, 2021.
<li>Saito, A., Sato, W., Yoshikawa, S., Rapid detection of neutral faces associated with emotional value among older adults, Journal of Gerontology: Psychological Sciences, 2021.
↑
</p><p><b>国際会議抄録</b> †
<li>Atsushi Omata, Shogo Ishikawa, Mia Kobayashi, Shinya Kiriyama, Collaborative Development of Outing Assistants for People with Dementia: a Case Study on a Co-design Approach, Asian CHI Symposium 2021, 2021.
<li>Miwako Honda, Development of educational system for paramedics specializing to dementia elderlies analyzed by artificial intelligence and its learning effects, Alzheimer's association international conference 2021, 2021.
<li>Miwako Honda, Masaki Kobayashi, Saki Une, Developing computing evaluation system of multi-modal communication skill of physicians in geriatric medicine by video analysis and eye-trackerwith artificial intelligence, European Geriatric Medicine Society Annual conference 2021, 2021.
↑
</p><p><b>国内会議抄録</b> †
<li>豊田真行, 石倉智貴, 趙崇貴, 高松淳, 小笠原司, タッチケアロボットのエンドエフェクタにおける接触面積・分布と快感情の関係, 日本機械学会ロボティクス・メカトロニクス講演会 2021（ROBOMECH2021）, 2021.
<li>松島佳苗, 長岡千賀, アン ミー, 伊藤凌太朗, 加藤寿宏, 吉川左紀子, 中澤篤志, 本田美和子, イブ ジネスト, 安藤夏子, 岩元美由紀, 自閉スペクトラム症児の母子相互作用のマルチモーダル分析 ～ 言語発達の水準が異なる2事例の比較 ～, 電子情報通信学会ヒューマンコミュニケーション基礎 (HCS)研究会, 121, 37HCS2021-3, pp.11-16, 2021.
<li>長岡千賀, 松島佳苗, アンミー, 伊藤凌太, 加藤寿, 吉川左紀子, 中澤篤志,本田美和子,イヴ・ジネスト, 安藤夏子, 岩元美由紀, 自閉スペクトラム症児の母子相互作用の マルチモーダル分析 －快情動の表出と顔向けの共起関係－, 日本心理学会第85回大会, 2021.
<li>豊田真行，湯口彰重，趙崇貴, 佐藤勇起，高松淳，中澤篤志，和田隆広，小笠原司, ユマニチュードの触れ方を再現するエンドエフェクタ開発へ向けた触れる動作における手のひらの接触面変化の解析, 第22回計測自動制御学会システムインテグレーション部門講演会（SI2021）, 2021.
<li>湯口彰重, 豊田真行, 高松淳, 小笠原司, 優しい介護ケアにおける触れる際の手のひらの接触領域の可視化と定量化, 第39回日本ロボット学会学術講演会（RSJ2021）, 2021.
<li>豊田真行, 石倉智貴, 趙崇貴, 高松淳, 小笠原司, タッチケアロボットのエンドエフェクタにおける接触面積・分布と快感情の関係, 日本機械学会ロボティクス・メカトロニクス講演会 2021（ROBOMECH2021）, 2021.
<li>竹内至生, 中澤篤志, StyleGANによる顔動作の感情変換, 第24回 画像の認識・理解シンポジウム(MIRU2021), pp.31-34, 2021.
<li>宮澤恒光, 沼田崇志, 中澤篤志, 深層学習による生活行動データからのパーソナリティ推定と行動マスキングによる説明可能性, 第24回 画像の認識・理解シンポジウム(MIRU2021), pp.31-24, 2021.
<li>原航基, 中澤篤志, 竹本あゆみ, ソーシャルロボットによる覚醒維持効果, 第39回日本ロボット学会学術講演会(RSJ2021), 2G1-04, 2021.
<li>岡部瑞稀, 中澤篤志, 渡辺裕貴, Styleパラメータ調整による生成学習を利用した関節データからの人物推定, 第24回 画像の認識・理解シンポジウム(MIRU2021), pp22-38, 2021.
<li>大嶋佑紀, 前田響介, 枝本祐典, 中澤篤志, 角膜表面反射画像からのシーン識別, 電子情報通信学会バイオメトリクス研究会 (BioX), 393, BioX2020-48, 2021.
<li>竹内至生, 中澤篤志, StyleGANによる顔動作の感情変換, IEICE MVE IMQ IE CQ, 391MVE2020-58, 2021.
<li>小野塚優志，中野目あゆみ，香山壮太，小俣敦士，石川翔吾，桐山伸也, 当事者本人の状態像理解を深める認知症ケアインタラクション表現モデルの構築, 第20回高齢社会デザイン研究会, 2021.
<li>松島佳苗, 長岡千賀, アン ミー, 伊藤凌太朗, 加藤寿宏, 吉川左紀子, 中澤篤志, 本田美和子, イブジネスト, 安藤夏子, 岩元美由紀, 自閉スペクトラム症児の母子相互作用のマルチモーダル分析 ～ 言語発達の水準が異なる2事例の比較 ～, 電子情報通信学会 ヒューマンコミュニケーション基礎(HCS)研究会, 121, 37, HCS2021, pp.11-16, 2021.
<li>徳元敦, 小俣敦士, 石川翔吾, 桐山伸也, 生活支援ケア向上のためのマルチモーダル心身環境センシングに基づく認知症高齢者の状態像理解, 高齢社会デザイン（ASD）, 2021.
<li>倉爪亮, Qi An, 拡張現実と分布型触覚センサを組み合わせた認知症ケア教育システムの開発, 第39回日本ロボット学会学術講演会, 2021.
<li>田中彰人, 安琪, 中嶋 一斗, 倉爪亮, ユマニチュードによる立ち上がり動作介助における介助者と被介助者の身体にかかる反力の解析, 第39回日本ロボット学会学術講演会, 2021.
<li>小俣敦士，石川翔吾，中野目あゆみ，香山壮太，宗形初枝，桐山伸也, 認知症ケアの組織学習を促すためのケアインタラクション分析に基づく映像学習環境の実践, みんなの認知症情報学会第４回年次大会, 2021.
<li>原航基, 中澤篤志, 竹本あゆみ, ソーシャルロボットによる眠気抑制効果, 電子情報通信学会HCGシンポジウム2021, 2021.
<li>岩元美由紀, 中澤篤志, 接触者の接触行動に対する非接触者の感情による生理反応に関する研究, 電子情報通信学会HCGシンポジウム2021, 2021.
<li>井上翔太, 中澤篤志, 岩元美由紀, 加藤寿宏, 吉川左紀子, 本田美和子, イブ ジネスト, 安藤夏子, ユマニチュードによる自閉スペクトラム障害児と親の行動変容に関する研究, 電子情報通信学会HCGシンポジウム2021, 2021.
<li>住岡英信，塩見昌裕，倉爪亮, マスクを用いたユマニチュード距離判定システムの開発, インタラクション2022, 2021.
<li>住岡英信，塩見昌裕，安琪，倉爪亮, 介護者と被介護者の身体的介助インタラクションを計測するための触覚センサシステムの開発, インタラクション2022, 2021.
<li>伊藤凌太朗, 松島佳苗, 長岡千賀, アン ミー, 宇田あかね, 加藤寿宏, 吉川左紀子, 中澤篤志, 本田美和子, イブ ジネスト, 安藤夏子, 岩元美由紀, 自閉スペクトラム症児の母子相互作用のマルチモーダル分析 ～ 言語コミュニケーションが困難な女児の事例を通して ～, 電子情報通信学会 ヒューマンコミュニケーション基礎(HCS)研究会, 2021.
↑
</p><p><b>その他の著書</b> †
<li>Yamamoto Takahisa, Nakazawa Atsushi, 研究ハイライト (第 26 回) General Improvement Method of Specular Component Separation Using High-Emphasis Filter and Similarity Function, 映像情報メディア学会誌= The journal of the Institute of Image Information and Television Engineers, 2021.
↑
招待講演 †
<li>Miwako Honda, The establishment process of Humanitude in Japan:* a key to success, 2021 Humanitude international Seminar, (2021.12.02).
<li>本田美和子, シンポジウム９ 共生の時代における認知症ケア：自立・自律の理念と 実践, 第40回日本認知症学会学術集会, (2021.11.26).
<li>中澤篤志, 優しい介護インタラクションの計算論的・脳科学的解明, 応用脳科学R&D研究会, (2021.10.20).
<li>Atsushi Nakazawa, ABC Conference Panelist, The 3rd International Conference on Activity and Behavior Computing, (2021.10.20).
<li>中澤篤志, 優しい介護インタラクションの計算論的・脳科学的解明, 京大テックフォーラム, (2021.09.13).
<li>本田美和子, 優しさを伝えるマルチモーダル・ケア技術：ユマニチュード, 第1回応用脳科学コンソーシアム：ブレインヘルスケア＆インフォメーションメディスン研究会, (2021.09.10).
<li>長岡千賀, 松島佳苗, 伊藤凌太朗, 加藤寿宏, 吉川左紀子, 中澤篤志, 本田美和子, 安藤夏子, 岩元美由紀, 自閉スペクトラム症児の母子相互作用のマルチモーダル分析快情動の表出と顔向けの共起関係, 日本心理学会大会発表論文集, (2021.09.01).
<li>Noeru Suzuki, Atsushi Nakazawa, GAN-based Style Transformation to Improve Gesture-recognition Accuracy, UBICOMP2021, オンライン, (2021. 08.24).
<li>石川翔吾, 介護現場における知識の創造と変容を支えるデータ利活用基盤, 第54回セマンティックWebとオントロジー研究会, オンライン, (2021.08.04).
↑
</p><p><b>受賞</b> †
<li>豊田真行, 湯口彰重，趙崇貴，佐藤勇起，高松淳，中澤篤志, 優秀講演賞, 第22回計測自動制御学会システムインテグレーション部門講演会（SI2021）,(2021.12.17).
<li>小俣敦士, 石川翔吾, 中野目あゆみ, 香山壮太, 宗形初枝, 坂根裕, 桐山伸也, 情報処理学会論文誌ジャーナル/JIP特選論文, 情報処理学会, (2022.02.15).
↑
</p><p><b>ワークショップ</b> †
<li>JRSJ OS ロボットと優しいマルチモーダル・コミュニケーション, オンライン, (2021.09.10).
</P>
                  </section>
                  <hr>				  
                  <section id="2020">
                     <h3>FY2020</h3>
<p><b>論文</b> †
<li>Wataru Sato, Shota Uono,Takanori Kochiyama. Neurocognitive mechanismsunderlying social atypicalities in autism: Weak amygdala’s emotional modulationhypothesis. Frontiers in Psychiatry, vol.11, pp.864, 2020.
<li>Wataru Sato, Koichi Murata, Yasuyuki Uraoka, Kazuaki Shibata, Sakiko Yoshikawa, Masafumi Furuta, Emotional valence sensing using a wearable facial EMGdevice. Scientific Reports, vol.11, pp.5757, 2020.
<li>Noeru Suzuki, Yuki Watanabe, Atsushi Nakazawa, GAN-based StyleTransformation? to Improve Gesture-recognition Accuracy, Proc. ACM Interact. Mob.Wearable Ubiquitous Technol. 4, 4, Article 154, 2020.
<li>Sato, W., Minemoto, K., Ikegami, A., Nakauma, M., Funami, T., Fushiki, T, Facial EMG correlates of subjective hedonic responses during food consumption, 12, 4, Article 1174, 2020.
<li>佐藤弥, 表情処理の神経時空間ダイナミクスの探究, 基礎心理学研究, 39, 1, pp92-95, 2020.
<li>Hsu, C.-T., Sato, W., Yoshikawa, S, Enhanced emotional and motor responses to live vs. videotaped dynamic facial expressions, Scientific Reports, 10, 1, Article 16825, 2020.
<li>Sato, W., Kochiyama, T., & Yoshikawa, S, Physiological correlates of subjective emotional valence and arousal dynamics while viewing films, Biological Psychology, 157, Article 107974, 2020.
<li>Kazuto Nakashima, Yumi Iwashita, Ryo Kurazume, Lifelogging caption generation via fourth-person vision in a human‒robot symbiotic environment, ROBOMECH Journal, 7, 1, pp1-15, 2020.
<li>Sato, Wataru, Sakiko Yoshikawa, Tohru Fushiki, Facial EMG activity is associated with hedonic experiences but not nutritional values while viewing food images, Nutrients, 13, 1, 11, 2020.
<li>Nunoi, Masato, Yoshikawa, Sakiko, Nakazawa, Atsushi, The Influence of the Other's Gaze Direction, Facial Expressions and the Participant's Posture on the Interpersonal Cognition on a Nursing Care Bed-Examination Using a Head- mounted Display, IEICE TRANSACTIONS ON FUNDAMENTALS OF ELECTRONICS COMMUNICATIO NS AND COMPUTER SCIENCES, 2, pp40-48, 2020.
<li>斉藤章江, 佐藤弥, 高齢者の表情処理, エモーション・スタディーズ, 6, 1, pp44-49, 2020.
<li>Akishige Yuguchi, Gustavo Alfonso Garcia Ricardez, Jun Takamatsu, Atsushi Nakazawa, and Tsukasa, Impression of Imitating Eyeblink and Nodding Using an Android for Attentive Listening in Face-to-face Communication, Frontiers in Robotics and AI, 2020.
<li>Saito, A., Sato, W., Yoshikawa, S, Older adults detect happy facial expressions less rapidly, Royal Society Open Science, 2020.
↑
</p><p><b>国際会議抄録</b> †
<li>Tomoki Hiramatsu, Masaya Kamei,Daiji Inoue, Akihiro Kawamura, Qi An, and Ryo Kurazume, Development of dementia care training system based on augmentedreality and whole body wearable tactile sensor, Proceedings of the 2020 IEEE/RSJInternational Conference on Intelligent Robots and Systems (IROS 2020), pp.4148-4154, ONLINE, 2020.
<li>Mitsuzum Yu, Irie Go Kimura Akisato, Nakazawa Atsushi, A Generative Self-Ensemble Approach To Simulated+ Unsupervised Learning, 2020 IEEE International Conference on Image Processing (ICIP), pp2151-2155,2020.
<li>Masato Kuno and Y. Ohmoto and T. Nishida, Developing Positive Attitudes Towards Cooperative Problem Solving by Linking Socio-emotional and Cognitive Intentions, conference, pp419-427,2020.
<li>Iwamoto Miyuki, Nakazawa Atsushi, Comparison of Gaze Skills Between Expert and Novice in Elderly Care, International Conference on Human-Computer Interaction, pp91-100, 2020.
<li>Hardjasa Louisa, Nakazawa Atsushi, An Examination of Gaze During Conversation for Designing Culture- Based Robot Behavior, International Conference on Human-Computer Interaction, pp475-488,2020.
<li>Masaki Kobayashi, Mio Ito, Miwako Honda, et al, The effect of multimodal comprehensive care methodology training on oral health care professionals' empathy for patients with dementia, Alzheimer Association International Conference, 2020.
<li>Masaki Kobayashi, Miwako Honda, et al., Reduction of family caregivers’ burden by an innovative video-based remote coaching system with a multimodal comprehensive care methodology for dementia: A feasibility study, International Congress of the European Union Geriatric Medicine Society, 2020.
<li>Aoyagi H, Takeuchi T, Okamoto E, Touyama H, Honda M, Effect of an educational method that uses role playing for care communication techniques with patients with dementia, The 34th Alzheimer’s disease international, 2020.
↑
</p><p><b>国内会議抄録</b> †
<li>桜栄 翔大, 中澤篤志, 歩行時におけるシーンの主観評価と注視行動の関係, 研究報告コンピュータビジョンとイメージメディア（CVIM）, 29, pp1-7, 2020-CVIM-222, Online, 2020.
<li>前田響介, 大嶋佑紀, 中澤篤志, Spatial Transformer Networksを用いた角膜表面反射画像からのシーン識別, 研究報告コンピュータビジョンとイメージメディア（CVIM）, 26, pp1-8, 2020-CVIM-222, Online, 2020.
<li>平松知樹, 亀井雅哉, 井上大路, 林拓真, 河村晃宏, 倉爪亮, 拡張現実と分布型触覚センサを組み合わせた認知症ケア教育システムの開発 -シナリオに基づく訓練システムと実証試験-, 日本機械学会ロボティクスメカトロニクス講演会2020, pp.1A1-D09, 2020.
<li>亀井雅哉, 平松知樹, 井上大路, 河村晃宏, 倉爪亮, 介護技術定量化のためのウェアラブル全身触覚センサの開発, 日本機械学会ロボティクスメカトロニクス講演会2020, pp.1A1-D10, 2020.
<li>湯口彰重, 高松淳, 中澤篤志, 小笠原司, 傾聴感を高めるためのアンドロイドの瞬目と頷きの模倣動作生成, 日本機械学会ロボティクス・メカトロニクス講演会2020, 2020.
<li>石倉智貴, 湯口彰重, 北村勇希, 趙崇貴, 丁明, 高松淳, 佐藤弥, 吉川左紀子, 小笠原司, 人の手を模したハンドを用いた優しい撫で動作の主観的，生理学的評価, ロボティクス・メカトロニクス講演会 2020（ROBOMECH2020）, 2020.
<li>久野 真登, 西田 豊明, 大本 義正, 社会感情的意図の循環的更新を用いた社会的関係の構築による積極性の誘発, 第34回人工知能学会全国大会論文集, pp. 3O5GS1301-3O5GS1301, 2020.
<li>小俣敦士, 石川翔吾, 中野目あゆみ, 香山壮太, 宗形初枝, 原寿夫, 桐山伸也, 竹林洋一, 多重思考モデルに基づく認知症ケアの内省を高度化させるマルチモーダル映像学習環境, 第34回人工知能学会全国大会論文集, pp. 4Rin146-4Rin146, 2020.
<li>前田響介, 大嶋佑紀, 中澤篤志, 角膜表面反射画像からのシーン識別, 第23回 画像の認識・理解シンポジウム(MIRU2020), IS3-3-24, 2020.
<li>竹内至生, 中澤篤志, 画像の感情惹起過程による分類と画像観察者の認知, 第23回 画像の認識・理解シンポジウム(MIRU2020), IS3-3-1,2020.
<li>鈴木乃依瑠, 渡辺祐貴, 中澤篤志, GAN に基づくスタイル変換による生成データを用いたジェスチャ認識の精度向上, 情報処理学会研究報告モバイルコンピューティングとパーベイシブシステム (MBL), 12, pp.1-8, 2020.
<li>佐藤弥, ヒトのように感情コミュニケーションするロボット構想, けいはんな R&Dフェス, 2020.
<li>Louisa Hardjasa, Atsushi Nakazawa, Cultural Differences in Gaze Behavior during Conversation and its Applications to Human-Robot Interaction, 電子情報通信学会HCGシンポジウム2020, HCG2020 A-7-5, 2020.
<li>岩元美由紀, 中澤篤志, 介護者とのコミュニケーションにおける被介護者の反応の分析, 電子情報通信学会HCGシンポジウム2020, HCG2020 A-6-1, 2020.
<li>竹内至生, 中澤篤志, 感情惹起に関わる画像中の内容と感情価判断の個人間のばらつき, 電子情報通信学会HCGシンポジウム2020, HCG2020 B-6-2, 2020.
<li>井上大路, AnQi?, 宮内翔子, 河村晃宏, 倉爪亮, 認知症介護動作中の触れるスキルの触覚グローブを用いた計測と評価, 第21回計測自動制御学会システムインテグレーション部門講演会 SI2020, 2C2-11, 2020.
<li>田中彰人, AnQi?, 宮内翔子, 河村晃宏, 倉爪亮, ユマニチュードの「触れる」スキルの定量化, 第21回計測自動制御学会システムインテグレーション部門講演会 SI2020, 2C2-12, 2020.
<li>阿比留幸貴, 財部弘幸, 本田美和子, 認知症高齢者救急搬送のためのユマニチュード教育受講と人工知能の映像解析によるその評価,第29回全国救急隊員シンポジウム, 2020.
↑
</p><p><b>その他の著書</b> †
<li>Kong, F., Heller, A. S., van Reekum, C. M., Sato, W., Positive neuroscience: the neuroscience of human flourishing, (2020.04.01).
<li>本田美和子, 金融取引における認知症高齢者支援の手引き, 全国地方銀行協会研修テキスト, (2020.12.10).
<li>本田美和子, 情報医学の視点から見たユマニチュード, Academia, (2020.12.22).
↑
</p><p><b>招待講演</b> †
<li>佐藤弥, 表情知覚：心理・神経メカニズムと非定型パタン, 中央大学研究開発機構公開研究会, 東京,(2020.09.18)
<li>本田美和子, ユマニチュードが挑むケア・イノベーション, 第2回日本ユマニチュード学会総会, オンライン, (2020.09.26).
<li>本田美和子, 優しさを伝えるケア技術・ユマニチュード, 第32回ハンセン病コ・メディカル学術集会, 香川, (2020.10.24).
<li>石川翔吾, 2040 AI・ICTの実用化はどこまで推進されるのか？, 第28回日本慢性期医療学会, オンライン, (2020,12.03)
<li>本田美和子, 人工知能で評価できる優しさを伝えるケア技術・ユマニチュード, 第24回日本統合医療学会学術大会, オンライン, (2020.12.13)
<li>本田美和子, 優しさを伝えるケア技術・ユマニチュード, 東京都理学療法学術大会, 東京, (2021.01.28).
                  </section>
                  <hr> 	
                  <section id="2019">
                     <h3>FY2019</h3>
<p><b>論文</b> †
<li>Wataru Sato, Takanori Kochiyama, Shota Uono, Reiko Sawada, Sakiko Yoshikawa, Amygdala activity related to perceived social support. Scientific Reports, 10, 2951, 2020.
<li>Wataru Sato, Takanori Kochiyama, Shota Uono, Sakiko Yoshimura, Yasutake Kubota, Reiko Sawada, Morimitsu Sakihama, Motomi Toichi, Atypical amygdala-neocortex interaction during dynamic facial expression processing in autism spectrum disorder. Frontiers in Human Neuroscience, 13, 351, 2019.
<li>Wataru Sato, Takanori Kochiyama, Shota Uono, Reiko Sawada, Yasutake Kubota, Sayaka Yoshimura, Motomi Toichi, Resting-state neural activity and connectivity associated with subjective happiness, Scientific Reports, 9, 12098, 2019.
<li>Wataru Sato, Shota Uono, The atypical social brain network in autism: Advances in structural and functional MRI studies, Current Opinion in Neurology, 32, 617-621, 2019.
<li>Wataru Sato, Takanori Kochiyama, Shota Uono, Reiko Sawada, Yasutake Kubota, Sayaka Yoshimura, S, Motomi Toichi, Widespread and lateralized social brain activity for processing dynamic facial expressions, Human Brain Mapping, 40, pp.3753-3768, 2019.
<li>佐藤弥, 表情認知の心理・神経メカニズム, 高次脳機能研究, 39, pp.70-78, 2019.
<li>Atsushi Nakazawa, Yu Mitsuzumi, Yuki Watanabe, Ryo Kurazume, Sakiko Yoshikawa, S, Miwako Honda, First-person video analysis for evaluating skill level in the humanitude tender-care technique, Journal of Intelligent & Robotic Systems, pp.1-16, 2019.
<li>Takahisa Yamamoto, Atsushi Nakazawa, General improvement method of specular component separation using high-emphasis filter and similarity function, ITE Transactions on Media Technology and Applications, Vol.7, No.2, pp.92-102, 2019.
<li>Takahisa Yamamoto, Atsushi Nakazawa, Fashion Style Recognition Using Component-Dependent Convolutional Neural Networks, In 2019 IEEE International Conference on Image Processing (ICIP), IEEE, pp.3397-3401, 2019.
<li>山本卓永, 中澤篤志, 入力画像の要素分割と各要素に対する学習を用いたファッションスタイル分類の性能向上, 電子情報通信学会論文誌 D, Vol.102, No.10, pp.639-650, 2019.
<li>Yuki Watanabe, Atsushi Nakazawa, Yu Mitsuzumi, Toyoaki Nishida, Spatio-temporal eye contact detection combining CNN and LSTM, In 2019 16th International Conference on Machine Vision Applications (MVA), IEEE, pp.1-7, 2019.
<li>Yuki Oshima, Atsushi Nakazawa, Eye Contact Detection from Third Person Video, Asian Conference on Pattern Recognition (ACPR), pp.667-677, 2019.
<li>Tetsuya Sano, Akishige Yuguchi, Gustavo Alfonso garcia Ricardez, Jun Takamatsu, Atsushi Nakazawa, Tsukasa Ogasawara, Evaluating Imitation of Human Eye Contact and Blinking Behavior Using an Android for Human-like Communication, In 2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN), IEEE, pp.1-6, 2019.
↑
</p><p><b>国際会議抄録</b> †
<li>Wataru Sato, Typical and atypical detection of emotional facial expressions, International Society for Research on Emotion (ISRE), 2019.
<li>Jun Takamatsu, Modeling Skills of Gentle Stroke Through Reproduction by a Robot and Subjective Evaluation, 2019 Japan-Korea Joint Workshop on Next Generation Robotics, 2019.
<li>Tomoki Hiramatsu, Development of AR care training system, The 15th Joint Workshop on Machine Perception and Robotics (MPR19), 2019.
<li>Atsushi Nakazawa, Miwako Honda, First-person camera system to evaluate Tender Dementia-care skill, Proceedings of the IEEE International Conference on Computer Vision Workshops, 2019.
<li>↑
</p><p><b>国内会議抄録</b> †
<li>佐藤弥, 自閉症の心理・神経メカニズム, 第37回日本ロボット学会, RSJ20191N3-06,東京, 2019.
<li>佐藤弥, 「無意識の感情」を探る ～脳内メカニズムの解明とセンシング技術の開発～, 京大式Think-up Camp！第1回, 東京, 2019.
<li>佐藤弥, 表情処理の神経時空間ダイナミクスの探究, 日本基礎心理学会第38回大会, 神戸, 2019.
<li>倉爪亮, 「触る」の定量化とユマニチュード教育システム, 第37回日本ロボット学会, RSJ20191N3-03,東京, 2019.
<li>高松淳, 豊島健太, 佐野 哲也, 湯口 彰重, 中澤 篤志, ガルシア リカルデス グスタボ アルフォンソ, 丁 明, 小笠原 司, ロボットによる見る・触れる動作の模倣とそれ を通じた評価, 第37回日本ロボット学会, RSJ20191N3-05,東京, 2019.
<li>枝本祐典, 中澤篤志, 西田豊明, 敵対的生成ネットワークを用いた角膜表面反射画像からのシーン識別, 研究報告コンピュータビジョンとイメージメディア（CVIM）, 12, pp1-8, 2019-CVIM-217, 東京, 2019.
<li>赤塚大地, 中澤篤志, 西田豊明, 深層学習を用いた動画像からのソーシャルタッチ検出, 研究報告コンピュータビジョンとイメージメディア（CVIM）, 14, pp1-8, 2019-CVIM-217, 東京, 2019.
<li>渡辺祐貴, 中澤篤志, 幸村琢, MotionGAN: 関節パラメータの敵対的学習による動作スタイル生成, 研究報告コンピュータビジョンとイメージメディア（CVIM）, 23, pp1-9, 北九州, 2019.
<li>布井雅人, 吉川左紀子, 中澤篤志, 介護ベッド上での対人認知 ～ 接近者の視線方向と観察者の体勢の影響 ～, 電子情報通信学会HCGシンポジウム2019, HCG2019 A-1-3, 広島, 2019.
<li>岩元美由紀, 中澤篤志, 口腔ケアにおける介護者及び被介護者間の視線行動の分析, 電子情報通信学会HCGシンポジウム2019, HCG2019 A-2-2, 広島, 2019.
<li>Louisa Hardjasa, Atsushi Nakazawa, A Cross-Cultural Examination of Gaze and Eye Behavior during Conversation, 電子情報通信学会HCGシンポジウム2019, HCG2019 A-2-1, 広島, 2019.
<li>渡辺祐貴, 中澤篤志, 幸村琢, Generative Adversarial Networks を用いたキーポーズからのキャラクタ動作生成, 研究報告コンピュータグラフィックスとビジュアル情報学 (CG), No.2, pp.1-7, 東京, 2019.
<li>鈴木乃依瑠, 渡辺祐貴, 中澤篤志, Style Transfer Network を用いた動作データの個性化によるジェスチャ認識の精度向上, 研究報告ユビキタスコンピューティングシステム (UBI), No.1, pp.1-7, 淡路島, 2019.
<li>小俣敦士, 石川翔吾, 宗形初枝, 本田美和子, 坂根裕, 桐山伸也, 認知症ケア高度化のための構造化映像を用いた協調的コーチング環境, 第37回日本ロボット学会, RSJ20191N3-04,東京, 2019.
<li>本田美和子, マルチモーダル・ケア技術の技術評価と臨床 効果, 第37回日本ロボット学会, RSJ20191N3-01,東京, 2019.
<li>井上翔太 中澤篤志, 岩元美由紀, 加藤寿宏, 吉川左紀子，本田美和子，イヴ・ジネスト, 安藤夏子, ユマニチュードによる自閉スペクトラム障害児と親の行動変容に関する研究, 第17回高齢社会デザイン研究会, 2019-ASD-14(12), 京都, 2019.
<li>本田美和子, ICUにおけるせん妄と身体抑制への多面的包括ケア方法論, 第1回日本ユマニチュード学会総会, 東京, 2019.
<li>平松知樹, 井上大路, 河村晃宏, 倉爪亮, 拡張現実と分布型接触センサを組み合わせた認知症ケア教育システムの開発, ロボティクス・メカトロニクス講演会講演概要集 2019, 一般社団法人 日本機械学会, 1A1-Q03, 広島, 2019.
<li>小俣敦士, 石川翔吾, 松井佑樹, 原寿夫, 宗形初枝, 中野目あゆみ, 坂根裕, 本田美和子, 桐山伸也, 竹林洋一, 認知症ケア協調学習環境における多重思考モデルに基づく指導知識の表出化, 人工知能学会全国大会論文集 一般社団法人 人工知能学会, 4Rin116-4Rin116, 新潟, 2019.
<li>小俣敦士, 石川翔吾, 原寿夫 , 宗形初枝 , 中野目あゆみ, 香山壮太, 坂根裕, 本田美和子, 桐山伸也, 竹林洋一, 認知症ケアの協調学習環境におけるコーチング知の可視化と分析, みんなの認知症情報学会第１回ポスター発表交流会, 東京, 2019.
<li>↑
</p><p><b>その他の著書</b> †
<li>Wataru Sato, Eva G. Krumhuber, Tjeerd Jellema, Justin H. G. Williams, Dynamic emotional communication, Lausanne: Frontiers Media SA, 2020.
<li>本田美和子, 優しさを伝えるマルチモーダル・ケア技術, 日本精神衛生会, vol177, 50(3), pp.39-43, 2019.
<li>本田美和子, イヴ・ジネスト, ユマニチュードという革命, 韓国語版DaeKwang? Medical, 2019.
<li>本田美和子, イヴ・ジネスト, 家族のためのユマニチュード, 韓国語版DaeKwang? Medical, 2019.
<li>大島寿美子, イヴ・ジネスト, 本田美和子,「絆」を築くケア技術 ユマニチュード：人のケアから関係性のケアへ, 誠文堂新光社, 2019.
<li>↑
</p><p><b>招待講演</b> †
<li>本田美和子, ユマニチュードと認知症, 日本学術会議学術フォーラム, 東京, (2020.02.14).
<li>中澤篤志, 認知症―予防と共生に向けて学術の取り組み, 日本学術会議学術フォーラム, 東京, (2020.02.14).
<li>中澤篤志, 「優しいケアコミュニケーション」とAI／ロボティックス, 第4回JST-NSF-DATAIA 国際連携シンポジウム, 東京, (2019.12.19).
<li>中澤篤志, 認知症の人との「コミュ力」を科学する～画像認識／センサによる人のコミュニケーションの理解～, 公開シンポジウム ～人とAIの未来スクール2019～, 東京, (2019.12.15).
<li>中澤篤志, 「優しい介護」の科学コミュニケーションスキルの定量化で何が得られるか？, 第９回PCIT-Japan & CARE-Japan合同研究会2019, 京都, (2019.11.30).
<li>本田美和子, 尊厳を回復させるケア「ユマニチュード」, 公益社団法人群馬県看護協会年次総会,群馬, (2019.11.13).
<li>本田美和子, 優しさを届けるケア技術ユマニチュード, 第33回日本手術看護学会年次大会, 岡山, (2019.10.11).
<li>本田美和子, 優しさを届けるケア技術ユマニチュード, 一般社団法人日本認知症ケア学2019年北海道ブロック大会, 北海道, (2019.09.29).
<li>Wataru Sato, Sensing emotional responses to food using physiological signals, 第2回COI学会, 東京, (2019.09.19).
<li>本田美和子, 優しさを届けるケア技術ユマニチュード, 日本キリスト者医科連盟第71回総会, 愛知, (2019.09.04).
<li>中澤篤志, 優しい介護「ユマニチュード」とロボティックス, 第37回日本ロボット学会学術講演会, 東京, (2019.09.03).
<li>本田美和子, 優しさを届けるケア技術ユマニチュード, 第21回日本医療マネジメント学会学術総会, 愛知, (2019.07.20).
<li>Wataru Sato, The neural substrate of subjective happiness 6th World Congress on Positive Psychology, Melbourne, Australia, (2019.07.20).
<li>Miwako Honda, Multimodal Comprehensive caremethodology Humanitude, International dementia care workshop, Incheon, Korea, (2019.06.17).
<li>中澤篤志, Computational Tender-care Science -- When 'Humanitude' and technology cross --, ATET : Advanced Technologies for Education and Therapy, 東京, (2019.05.24).
<li>本田美和子, かけがえのない記憶の再興戦略, 公益社団法人全日本鍼灸学会第68会学術大会, 愛知, (2019.05.12).

</p><p><b>受賞</b> †
<li>渡辺祐貴, 中澤篤志, 幸村琢, 優秀研究発表賞, 情報処理学会コンピュータグラフィックスとビジュアル情報学研究会 (CGVI), 北九州, (2019.11.08).
<li>渡辺祐貴, 中澤篤志, 幸村琢, 研究奨励賞, 情報処理学会研究報告コンピュータビジョンとイメージメディア (CVIM), 北九州, (2019.11.08).
<li>枝本 祐典, 中澤 篤志, 西田 豊明, CVIM卒論セッション優秀賞, 情報処理学会研究報告コンピュータビジョンとイメージメディア（CVIM）, 東京, (2019.05.30).
<li>三鼓悠, 入江豪, 中澤篤志, 木村昭悟, 研究奨励賞, 電子情報通信学会PRMU, 東京, (2019.03.17).

</p><p><b>ワークショップ</b>  †
<li>第37回日本ロボット学会学術講演会オーガナイズドセッション・優しい介護「ユマニチュード」とロボティックス, 早稲田大学, 東京, (2019.09.04).
<p>
                  </section>
                  <hr>
                  <section id="2018">
                     <h3>FY2018</h3>
<p><b>論文</b> †
<li>Takahisa Yamamoto, Atsushi Nakazawa, General Improvement Method of Specular Component Separation Using High-Emphasis Filter and Similarity Function, ITE Transactions on Media Technology and Applications, Volume7，Issue2，pp.92-102, 2019.
<li>Kazunari Kitazumi，Atsushi Nakazawa，Robust Pupil Segmentation and Center Detection from Visible Light Images Using Convolutional Neural Network, 2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC), IEEE, pp.862-868，2018.
<li>Yu Mitsuzumi，Atsushi Nakazawa, Eye contact detection algorithms using deep learning and generative adversarial networks, 2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC). IEEE, pp.3927-3931, 2018.
<li>Taishi Ogawa, Atsushi Nakazawa, Toyoaki Nishida, Point of gaze estimation using corneal surface reflection and omnidirectional camera image, IEICE Transactions on Information and Systems, vol. E101-D, No.5, pp.1278-1287, 2018.
<li>Atsushi Nakazawa, Ryo Kurazume, Miwako Honda, Sato Wataru, Shogo Ishikawa, Sakiko Yoshikawa, Mio Ito, Computational Tender-Care Science: Computational and Cognitive Neuroscientific Approaches for Understanding the Tender Care, Workshop on Elderly Care Robotics - Technology and Ethics (WELCARO) in ICRA2018, 2018.
<li>Atsushi Nakazawa, Ryo Krazume, Miwako Honda, Wataru Sato Shogo Ishikawa, Sakiko Yoshikawa, Mio Ito, Computational Tender-Care Science: Computational and Cognitive Neuroscientific Approaches for Understanding the Tender Care, IUI Workshop on Symbiotic Interaction and Harmonius Collaboration for Wisdom Computing, Vol.1, pp.1-9, 2018.
<li>Kenta Toyoshima, Ming Ding, Jun Takamatsu, Tsukasa Ogasawara, What is Required for a Robot to Gently Stroke a Human using its Hand, Workshop on Elderly Care Robotics Technology and Ethics (WELCARO) in ICRA2018, 2018.
<li>Miyuki Iwamoto, Noriaki Kuwahara, Investigation of Quantification of Suitable Photo for Conversation Support with Elderly People by Emotion of Youth, Computers Helping People with Special Needs, (ICCHP) , pp. 434-437, 2018.
<li>土肥眞奈, 本田美和子, 林夏希，春名明美，伊藤美緒，佐々木晶世，叶谷由佳，認知症高齢者を在宅介護する家族にユマニチュード®の基本技術を伝えたあとの家族の受け止め,日本健康医学会雑誌，Vol.27, No.2, pp.159-165, 2018.
<li>Wataru Sato, Sylwia Hyniewska, Kazusa Minemoto, Sakiko Yoshikawa, Facial expressions of basic emotions in Japanese laypeople, Frontiers in Psychology, Vol.10, No.259, 2019.
↑
</p><p><b>国際会議抄録</b> †
<li>Miwako Honda, Yves Gineste, Development of the highly reproducible standardized evaluation system for dementia care by thinking model of artificial intelligence, European Union Geriatric Medicine Society, Berlin, 2018.
<li>Kazuto Nakashima, Yumi Iwashita, Akihiro Kawamura, Ryo Kurazume, Fourth-person Captioning: Describing Daily Events by Uni-supervised and Tri-regularized Training, The 2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC 2018), pp. 2122-2127, Miyazaki, 2018.
<li>Miwako Honda, Effect of multimodal comprehensive care methodology training on both delirium and physical restraints in intensive care unit, American Delirium Society, San Francisco, 2018.
<li>Miwako Honda, Yves Gineste, Video-based care performance data analysis of professional caregivers with manual and artificial intelligence, Gerontological Society of America, Boston, 2018.
<li>Miwako Honda, Yves Gineste, Concise multimodal communication training for family caregivers reduced their burden and BPSD of care receivers, Gerontological Society of America, Boston, 2018.
<li>Kazuto Nakashima, Describing Daily Events in Intelligent Space via Fourth-person Perspective Images, The 14th Joint Workshop on Machine Perception and Robotics (MPR18), Fukuoka, 2018.
↑
</p><p><b>国内会議抄録</b> †
<li>北角一哲, 中澤篤志, 西田豊明, 深層学習を用いた可視光画像からの瞳孔検出と注視点推定への応用, 電子情報通信学会技術研究報告, Vol.117, No.392, pp.93-99, 大阪2018.
<li>江川佳輝, 小川太士, 中澤篤志, 深層学習を用いた自己撮影画像の撮影位置検索, 電子情報通信学会技術研究報告, Vol.117, No.392, pp.333-337, 大阪, 2018.
<li>三鼓悠, 中澤篤志, 西田豊明, 半教師あり学習によるアイコンタクト検出, 研究報告コンピュータビジョンとイメージメディア（CVIM）, Vol.2018-CVIM-210, No.57, pp.1-7, 大阪, 2018.
<li>岩元美由紀,　中澤篤志, コミュニケーションにおいて「見つめる」ことの重要性の検証, ヒューマンインターフェースシンポジウム, 筑波, 2018.
<li>岩元美由紀, 中澤篤志, 世代間コミュニケーションにおいて「見つめる」ことの重要性の検証, 電子情報通信学会HCGシンポジウム2018, HCG2018 A-3-3, 三重, 2018.
<li>平岡達也, 岩元美由紀, 中澤篤志, 桑原教彰, ウェアラブルなメガネ型一人称視点カメラデバイスの開発とその評価, 第164回ヒューマンインターフェース学会研究会 「高齢者、障がい者支援技術および一般(SIG-ACI-23)」, 京都, 2018.
<li>松井佑樹，小俣敦士，石川翔吾，原寿夫，宗形初枝，中野目あゆみ，香山壮太，坂根裕，本田美和子，桐山伸也，竹林洋一，多重思考モデルを用いた認知症ケアコーチング知の表出化に基づく協調学習環境の構築, 第14回高齢社会デザイン研究会, 2018-ASD-14(6), 東京, 2018.
<li>石川翔吾，松井佑樹，小俣敦士，香山壮太，中野目あゆみ，宗形初枝，坂根裕，本田美和子, 認知症ケア高度化に向けた多重思考モデルを用いた協調的コーチング支援環境の構築, HCGシンポジウム2018, HCG2018 A-3-5, 三重, 2018.
<li>平松知樹, 井上大路, 倉爪亮, 認知症患者ケアのためのウェアラブル触覚センサの開発, 電子情報通信学会HCGシンポジウム2018, HCG2018 A-3-6, 三重, 2018.
<li>中嶋一斗, 岩下友美, 倉爪亮, 第四人称視点に基づく情報構造化空間の状況説明文生成, 第36回日本ロボット学会学術講演会, RSJ2018AC2C1-03, 東京, 2018.
<li>佐野哲也, 湯口彰重, 中澤篤志, Gustavo Alfonso Garcia Ricardez, 高松淳, 小笠原司, 人の視線計測に基づく会話時の視線提示が可能なアンドロイドシステム, 第19回計測自動制御学会システムインテグレーション部門講演会（SI2018）, 1C5-09, 大阪, 2018.
<li>松井佑樹，小俣敦士，石川翔吾，原寿夫，宗形初枝，中野目あゆみ，香山壮太，島野光正，桐山伸也，竹林洋一, 認知症ケアコーチング支援のためのMinskyの感情思考モデルに基づくケア知の表現, みんなの認知症情報学会第１回年次大会, No.8 静岡, 2018.
<li>小俣敦士，松井佑樹，石川翔吾，桐山伸也，宗形初枝，中野目あゆみ，香山壮太，島野光正，原寿夫，坂根裕，本田美和子，竹林洋一, 認知症ケアにおける自己表現モデルに基づく協調学習環境デザイン, みんなの認知症情報学会第1回年次大会, No.6, 静岡, 2018.
<li>石川翔吾，佐々木勇輝，桐山伸也，本田美和子，Yves Gineste，竹林洋一, 感情思考モデルに基づくマルチモーダル認知症ケア知の共創, 3Pin1-47, 第32回人工知能学会全国大会, 鹿児島, 2018.
<li>小俣敦士，石川翔吾，宗形初枝，中野目あゆみ，伊東美緒，坂根裕，本田美和子，原寿夫，桐山伸也，竹林洋一, 個性に基づくケアのための認知症ケア協調学習環境の構築と実践, 第32回人工知能学会全国大会, 3Pin1-46, 鹿児島, 2018.
↑
</p><p><b>その他の著書</b> †
<li>本田美和子, 認知症の人へのさまざまなアプローチ-1.ユマニチュード, 最新介護福祉士養成講座13・認知症の理解,第4章第5節,介護福祉士養成講座編集委員会, pp.217～220, 2019.
<li>本田美和子, わが国におけるユマニチュード導入の成果と今後の展望「自由・平等・博愛・優しさ」を分かち合う組織の実現に向けて, 看護管理, 第29巻第2号, 医学書院, pp.10～16, 2019.
<li>本田美和子, 伊東美緒, ユマニチュードと看護, 書籍　医学書院, 2019.
<li>認知症の人へのさまざまなアプローチ-1.ユマニチュード, 最新介護福祉士養成講座13・認知症の理解, 第4章第5節, 介護福祉士養成講座編集委員会, pp.217～220, 2019
<li>嶺本和沙・佐藤弥, 日本人の基本6感情の表情は「エクマン理論」に従うか？－人工知能を用いて検証, academist Journal, 2019.
<li>石川翔吾，竹林洋一, スーツケースワード，ゴール，感情，多重思考モデル─認知症情報学によるInterior Grounding ─，人工知能学会誌，Vol.33, No.3, pp.307-315, 2018.
<li>イヴ・ジネスト，ロゼット・マレスコッティ，本田美和子, ユマニチュードを語る 市民公開講座でたどる〈それぞれのユマニチュード〉の歩み，日本評論社, 2018.
<li>本田美和子　生涯教育シリーズ95「認知症トータルケア」Ⅷ.治療とケア－認知症ケア・ユマニチュード, 日本医師会雑誌, 第147巻, 特別号(2), 日本医師会, pp.264～265, 2018.
<li>本田美和子　ユマニチュード－優しさを伝え、医療の現場を変えるケア技法, 患者安全推進ジャーナル別冊・高齢患者のリスクマネジメント, 公益社団法人日本医療機能評価機構, pp.39, 2018.
<li>本田美和子, イヴ・ジネスト, 家族のためのユマニチュード, 書籍 誠文堂新光社, 2018.
↑
</p><p><b>招待講演</b> †
<li>中澤篤志，倉爪亮, 認知症対応を科学する, 自由民主党　データヘルス推進特命委員会 科学的介護等ＷＧ, 東京, (2019.03.26).
<li>本田美和子　Yves Gineste, ユマニチュードによる認知症ケア, 京都大学産学官コンソーシアムイノベーション会議, 京都市, (2019.03.20).
<li>中澤篤志, 人工知能によって「人を見る」, 学習院大学計算機センター　第30回特別研究会, 東京, (2018.12.22).
<li>佐藤弥, 表情認知の心理・神経メカニズム, 第42回日本高次脳機能障害学会学術総会, 神戸, (2018.12.07).
<li>本田美和子, ユマニチュードの哲学と実践, 京都大学こころの未来研究センター　こころ塾, 京都市, (2018.12.01).
<li>本田美和子, 特別講演・認知症におけるユマニチュード, 平成30年度日本統合医療学会京滋支部・阪南支部・阪南支部ヨーガ部会合同総会, 大阪市, (2018.11.03).
<li>本田美和子, 「優しさを伝えるケア技術・ユマニチュード」～人のもつ力を最大限に引き出すための関係性の哲学と基本技術, 第20回日本骨粗鬆学会, 長崎市, (2018.10.27).
<li>中澤篤志，人の目の観察により導き出されるもの ～ 注視・環境情報・介護スキルの推定 ～ 電子情報通信学会ヒューマン情報処理研究会（HIP），日本光学会視覚研究グループ 京都, (2018.10.22).
<li>中澤篤志, 「優しい介護」インタラクションの計算的・脳科学的解明 ～パターン認識は介護に何ができるのか？～, 第17回情報科学技術フォーラム, 福岡, (2018.09.20).
<li>岩元美由紀, 人にやさしい介護方法の定量化, 日韓共同シンポジウム, 大邱, 大韓民国, (2018.09.16).
<li>Wataru Sato, Measuring emotional valence using facial EMG, Sao Paulo School of Advanced Science on Social and Affective Neuroscience, Sao Paulo, Brazil, (2018.08.30).
<li>Wataru Sato, The psychological and neural mechanisms of rapid emotional responses, Sao Paulo School of Advanced Science on Social and Affective Neuroscience, Sao Paulo, Brazil, (2018.08.29).
<li>Wataru Sato, The psychological and neural mechanisms of atypical social functioning in autism spectrum disorder, Sao Paulo School of Advanced Science on Social and Affective Neuroscience, Sao Paulo, Brazil, (2018.08.27).
<li>中澤篤志, 優しい介護インタラクションの計算的・脳科学的解明, 情報処理学会　研究報告高齢社会デザイン（ASD） 研究会, 函館, (2018.08.24).
<li>Miwako Honda, Concise multimodal communication training for family caregivers reduced their care burden and behavioral psychological symptoms of dementia (BPSD) of care receivers, Asian Family Summit, Hong Kong, (2018.08.19).
<li>本田美和子, 家族のためのユマニチュード🄬介護技術, 平成３０年度網走市民大学講座, 網走市, (2018.06.22).
<li>本田美和子, 教育講演「多職種で実践するユマニチュード」, 第9回日本プライマリ・ケア連合学会学術大会, 三重県, (2018.06.16).
<li>本田美和子, ユマニチュードから考える「認知症に優しいまち」, NHK ハートフォーラム, 福岡市, (2018.06.02).
↑
</p><p><b>受賞</b> †
<li>石川 翔吾，松井 佑樹，小俣 敦士，香山 壮太，中野目 あゆみ，宗形 初枝，坂根 裕，本田 美和子, HCGシンポジウム2018特集テーマセッション賞, HCGシンポジウム2018, 三重, (2018.12.13).
<li>Kazuto Nakashima, Best Poster Session Award, The 14th Joint Workshop on Machine Perception and Robotics (MPR18), Fukuoka, (2018.10.17).
<li>Atsushi Nakazawa, Advanced Robotics, Best Paper Award, Robotics Society Japan, Aichi, (2018.06.23).
<li>↑
<li>ワークショップ †
<li>ユマニチュード講習会, 京丹後市セントラレ, 京都, (2019.03.03).
<li>ユマニチュード研修, 京都大学病院研修室, 京都, (2018.07.14).
<li>ICRA2018 Workshop on Elderly Care Robotics – Technology and Ethics (WELCARO), Australia, (2018.05.22).
</p>
                  </section>
                  <hr>
                  <section id="2017">
                     <h3>FY2017</h3>
<p><b>国際会議抄録</b>
<li>Akishige Yuguchi, Gaze Calibration for Human-Android Eye Contact Using a Single Camera, IEEE International Conference on Robotics and Biomimetics (ROBIO 2017), Macau SAR, China, 2018.
<li>Atsushi Nakazawa, Computational Tender-Care Science: Computational and Cognitive, Neuroscientific Approaches for Understanding the Tender Care, IUI 2018 Workshop on, Symbiotic Interaction and Harmonious Collaboration for Wisdom Computing, NII, Tokyo, 2018.
</p>

<p><b>国内会議抄録</b>
<li>Wataru Sato, The psychological and neural mechanisms of impaired unconscious joint attention in autism, What is Unique and What is Typical of Human Mind?, Kyoto University, Kyoto, 2018.
<li>石川翔吾, マルチモーダルケア技法による自閉症児への介入効果検証に向けた基礎的検討, 第14回こども学会議, 岡山県環太平洋大学, 岡山, 2017.
</p>
<p><b>その他の著書</b>
<li>中澤篤志，ユマニチュードを行動から，脳から知りたい，医学界新聞，3254号，pp.13，2018.
<li>Atsushi Nakazawa, Takaaki Shiratori, Motion Capture, The Wiley Handbook of Human Computer Interaction (Kent L. Norman and Jurek Kirakowski (ed.)), pp.405-420, 2018.
<li>Christian Nitschke, Atsushi Nakazawa, Corneal Imaging, The Wiley Handbook of Human Computer Interaction (Kent L. Norman and Jurek Kirakowski (ed.)), pp.445-452, 2018.
</p><p>
<b>招待講演</b>
<li>本田美和子, 優しさを伝え技術, 第３６回沖縄県人工透析研究会, 那覇　沖縄コンベンションセンター, 沖縄, (2018.03.11).
<li>本田美和子, 優しさを伝えるケア技術～専門職にも、家族にも～, 日本在宅医学会　第3回地域フォーラムin三重, 津　三重県総合文化センター, 三重, (2018.02.03).
<li>中澤篤志, 人の視覚情報の可視化と優しい介護技術学習への展開, 破壊的イノベーションがもたらすデジタル社会研究会, パナソニック　Wonder LAB Osaka, 大阪, (2018.01.22).
<li>本田美和子, 優しさを伝えるケア技術とその客観的評価, 日本医療マネジメント学会　第16回九州・山口連合大会, 別府　国際コンベンションセンター, 大分, (2017.12.02).
<li>Miwako Honda, Intelligence artificielle et soins, developpement d’un outil elearning, 10e colloque Approches Non-medeicamenteuses, Cite de science, Paris, (2017.11.10).
<li>中澤篤志, The environmental light and your eye -- retrieving your vision using computer vision --, CiNet? Talk Series, CiNet? 脳情報通信融合研究センター, 大阪, (2017.10.13).
</p><p>
<b>その他の成果</b>
<li>北角一哲, 中澤篤志, 西田豊明, 深層学習を用いた可視光画像からの瞳孔検出と注視点推定への応用, (メディアエクスペリエンス・バーチャル環境基礎) 電子情報通信学会技術研究報告 = IEICE technical report :信学技報 0913-5685 電子情報通信学会, Vol.117, No.392, pp.93-99 https://ci.nii.ac.jp/naid/40021465187/, (2018.01.18).
<li>三鼓悠, 中澤篤志, 西田豊明, 半教師あり学習によるアイコンタクト検出, (メディアエクスペリエンス・バーチャル環境基礎) 電子情報通信学会技術研究報告 = IEICE technical report : 信学技報0913-5685 電子情報通信学会, Vol.117, No.392, pp.339-345, https://ci.nii.ac.jp/naid/40021465692, (2018.01.18).
<li>江川佳輝, 小川太士, 中澤篤志, 深層学習を用いた自己撮影画像の撮影位置検索, (メディアエクスペリエンス・バーチャル環境基礎) 電子情報通信学会技術研究報告 = IEICE technical report : 信学技報 0913-5685 電子情報通信学会, Vol.117, No.392, pp.333-337, https://ci.nii.ac.jp/naid/400, (2018.01.18).
<li>三鼓悠, 中澤篤志, 西田豊明, 半教師あり学習によるアイコンタクト検出, (パターン認識・メディア理解) 電子情報通信学会技術研究報告 = IEICE technical report : 信学技報 0913-5685 電子情報通信学会, 117 391 339-345 https://ci.nii.ac.jp/naid/40021464368/ , (2018.01.18).
<li>中澤篤志, 山崎俊彦, 松下康之, 安倍満, 舩冨卓哉, 木村昭悟, 内田誠一, 前田栄作, PRMU応用研究におけるオープンアイデア : PRMU第二期グランドチャレンジ, (パターン認識・メディア理解) 電子情報通信学会技術研究報告 = IEICE technical report : 信学技報 0913-5685 電子情報通信学会, Vol.117, No.362 pp.41-43, https://ci.nii.ac.jp/naid/40021432486/, (2017.12.17).
</p>
                  </section>
                  <hr>				  
               </section>
            </div>
         </div>
      </div>
<!----------------------------------------------------------------------------------------------------------->
      <footer id="footer">
         <div class="container-fluid">
            <div class="row-fluid">
               <div class="span5">
                  <h3>Contact Information</h3>
                  <b>Atsushi Nakazawa<br>
                  nakazawa.atsushi@okayama-u.ac.jp</b>
                  <a href="mailto:nakazawa.atsushi@okayama-u.ac.jp">Email</a>
               </div>
               <div class="span5">
                  <h3>Address</h3>
                  Graduate School of Interdisciplinary Science and Engineering in Health Systems, Okayama University<br>
                  700-8530 Tsushima Naka 3-1-1, Kita-ku, Okayama, Japan<br>
                  </p>
               </div>
            </div>
         </div>
      </footer>

      <!-- Le javascript
         ================================================== -->
      <!-- Placed at the end of the document so the pages load faster -->
      <script src="js/jquery-1.9.1.min.js"></script>
      <script src="js/bootstrap.min.js"></script>
      <script>
         $(document).ready(function() {
             $(document.body).scrollspy({
                 target: "#navparent"
             });
         });
         
      </script>
   </body>
</html>